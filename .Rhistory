data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, train_id_task2); print(round(mean_loss_informed_task2, 3))
window_length <- 6 # use data of the past 6 months for predictions
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, train_id_task2); print(round(mean_loss_informed_task2, 3))
window_length <- 7 # use data of the past 6 months for predictions
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, train_id_task2); print(round(mean_loss_informed_task2, 3))
print(round(mean_loss_informed_task2, 3))
for (window_length in 2:4) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, train_id_task2); print(round(mean_loss_informed_task2, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
loss_means
window_length <- 4 # use data of the past 6 months for predictions
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, train_id_task2); print(round(mean_loss_informed_task2, 3))
print(round(mean_loss_informed_task2, 3))
train_id_task2 <- 394:444 # test set (01/17-12/19)
train_id_task1 <- 445:488 # test set (01/17-12/19)
window_months <- 386:495 # 386:495 # data contains obs. for month_id 121 onwards, 7-step ahead forecast exists for 128 onwards; data for South Sudan (incl. 7 step-ahead forecast) only available from 386 onwards
# TADDA-scores that were used in paper: TADDA1 = TADDA1_L1, TADDA2 = TADDA2_L1, each with epsilon = 0.048
BA_names <- c("BA_SE", "BA_TADDA1_L1")#, "BA_TADDA2_L1")
loss_means <- c(NA, NA, NA)
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, train_id_task2); print(round(mean_loss_informed_task2, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
# read in data
data_fatalities <- read.csv(paste("Data/data_fatalities.csv"))[,-1]
# set parameters & choose task windows
epsilon <- 0.048
window_length <- 4 # use data of the past 6 months for predictions
month_id_task1 <- 490:495 # true future of challenge (10/20-03/21)
month_id_task2 <- 445:480 # test set (01/17-12/19)
train_id_task2 <- 394:444 # test set (01/17-12/19)
train_id_task1 <- 445:488 # test set (01/17-12/19)
window_months <- 386:495 # 386:495 # data contains obs. for month_id 121 onwards, 7-step ahead forecast exists for 128 onwards; data for South Sudan (incl. 7 step-ahead forecast) only available from 386 onwards
# TADDA-scores that were used in paper: TADDA1 = TADDA1_L1, TADDA2 = TADDA2_L1, each with epsilon = 0.048
BA_names <- c("BA_SE", "BA_TADDA1_L1")#, "BA_TADDA2_L1")
loss_means <- c(NA, NA, NA)
# initialise objects
predictions_uninformed <- predictions_informed <- predictions_combined <- list()
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, window_months); print(round(mean_loss_informed_task2, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
rownames(lmeans) <- NULL
loss_means <- loss_means[-1,]
loss_means
# set parameters & choose task windows
epsilon <- 0.048
window_length <- 4 # use data of the past 6 months for predictions
month_id_task1 <- 490:495 # true future of challenge (10/20-03/21)
month_id_task2 <- 445:480 # test set (01/17-12/19)
train_id_task2 <- 394:444 # test set (01/17-12/19)
train_id_task1 <- 445:488 # test set (01/17-12/19)
window_months <- 386:495 # 386:495 # data contains obs. for month_id 121 onwards, 7-step ahead forecast exists for 128 onwards; data for South Sudan (incl. 7 step-ahead forecast) only available from 386 onwards
# TADDA-scores that were used in paper: TADDA1 = TADDA1_L1, TADDA2 = TADDA2_L1, each with epsilon = 0.048
BA_names <- c("BA_SE", "BA_TADDA1_L1")#, "BA_TADDA2_L1")
loss_means <- c(NA, NA, NA)
# initialise objects
predictions_uninformed <- predictions_informed <- predictions_combined <- list()
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, 393:495); print(round(mean_loss_informed_task2_train, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, 400:495); print(round(mean_loss_informed_task2_train, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
# set parameters & choose task windows
epsilon <- 0.048
window_length <- 4 # use data of the past 6 months for predictions
month_id_task1 <- 490:495 # true future of challenge (10/20-03/21)
month_id_task2 <- 445:480 # test set (01/17-12/19)
train_id_task2 <- 394:444 # test set (01/17-12/19)
train_id_task1 <- 445:488 # test set (01/17-12/19)
window_months <- 386:495 # 386:495 # data contains obs. for month_id 121 onwards, 7-step ahead forecast exists for 128 onwards; data for South Sudan (incl. 7 step-ahead forecast) only available from 386 onwards
# TADDA-scores that were used in paper: TADDA1 = TADDA1_L1, TADDA2 = TADDA2_L1, each with epsilon = 0.048
BA_names <- c("BA_SE", "BA_TADDA1_L1")#, "BA_TADDA2_L1")
loss_means <- c(NA, NA, NA)
# initialise objects
predictions_uninformed <- predictions_informed <- predictions_combined <- list()
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, 400:495); print(round(mean_loss_informed_task2_train, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
# set parameters & choose task windows
epsilon <- 0.048
window_length <- 4 # use data of the past 6 months for predictions
month_id_task1 <- 490:495 # true future of challenge (10/20-03/21)
month_id_task2 <- 445:480 # test set (01/17-12/19)
train_id_task2 <- 394:444 # test set (01/17-12/19)
train_id_task1 <- 445:488 # test set (01/17-12/19)
window_months <- 386:495 # 386:495 # data contains obs. for month_id 121 onwards, 7-step ahead forecast exists for 128 onwards; data for South Sudan (incl. 7 step-ahead forecast) only available from 386 onwards
# TADDA-scores that were used in paper: TADDA1 = TADDA1_L1, TADDA2 = TADDA2_L1, each with epsilon = 0.048
BA_names <- c("BA_SE", "BA_TADDA1_L1")#, "BA_TADDA2_L1")
loss_means <- c(NA, NA, NA)
# initialise objects
predictions_uninformed <- predictions_informed <- predictions_combined <- list()
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, 386:444); print(round(mean_loss_informed_task2_train, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
# read in data
data_fatalities <- read.csv(paste("Data/data_fatalities.csv"))[,-1]
# set parameters & choose task windows
epsilon <- 0.048
window_length <- 4 # use data of the past 6 months for predictions
month_id_task1 <- 490:495 # true future of challenge (10/20-03/21)
month_id_task2 <- 445:480 # test set (01/17-12/19)
train_id_task2 <- 394:444 # test set (01/17-12/19)
train_id_task1 <- 445:488 # test set (01/17-12/19)
window_months <- 386:495 # 386:495 # data contains obs. for month_id 121 onwards, 7-step ahead forecast exists for 128 onwards; data for South Sudan (incl. 7 step-ahead forecast) only available from 386 onwards
# TADDA-scores that were used in paper: TADDA1 = TADDA1_L1, TADDA2 = TADDA2_L1, each with epsilon = 0.048
BA_names <- c("BA_SE", "BA_TADDA1_L1")#, "BA_TADDA2_L1")
loss_means <- c(NA, NA, NA)
# initialise objects
predictions_uninformed <- predictions_informed <- predictions_combined <- list()
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, 400:444); print(round(mean_loss_informed_task2_train, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
# read in data
data_fatalities <- read.csv(paste("Data/data_fatalities.csv"))[,-1]
# set parameters & choose task windows
epsilon <- 0.048
window_length <- 4 # use data of the past 6 months for predictions
month_id_task1 <- 490:495 # true future of challenge (10/20-03/21)
month_id_task2 <- 445:480 # test set (01/17-12/19)
train_id_task2 <- 394:444 # test set (01/17-12/19)
train_id_task1 <- 445:488 # test set (01/17-12/19)
window_months <- 386:495 # 386:495 # data contains obs. for month_id 121 onwards, 7-step ahead forecast exists for 128 onwards; data for South Sudan (incl. 7 step-ahead forecast) only available from 386 onwards
# TADDA-scores that were used in paper: TADDA1 = TADDA1_L1, TADDA2 = TADDA2_L1, each with epsilon = 0.048
BA_names <- c("BA_SE", "BA_TADDA1_L1")#, "BA_TADDA2_L1")
loss_means <- c(NA, NA, NA)
# initialise objects
predictions_uninformed <- predictions_informed <- predictions_combined <- list()
for (window_length in 4:10) {
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
# compute losses for each prediction horizon and loss function
# SE_loss_uninformed_df <- loss_df(data_predictions_uninformed, "SE")
# TADDA1_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA1_L1")
# TADDA2_L1_loss_uninformed_df <- loss_df(data_predictions_uninformed, "TADDA2_L1")
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# TADDA2_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA2_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, 400:444); print(round(mean_loss_informed_task2_train, 3))
loss_means <- rbind(loss_means, c(window_length, mean(mean_loss_informed_task2_train[1, c(4,7,10,13,16,19)]), mean(mean_loss_informed_task2_train[2, c(4,7,10,13,16,19)+1])))
# write.csv(round(mean_loss_uninformed_task2, 3), "mean_loss_uninformed_task2.csv")
# write.csv(round(mean_loss_informed_task2, 3), paste("mean_loss_informed_task2_s", window_length, ".csv", sep = ""))
}
rownames(lmeans) <- NULL
loss_means <- loss_means[-1,]
loss_means
loss_df <- function(data_predictions, loss_fun) {
loss <- lapply(1:7, function(s) compute_losses(s, loss = loss_fun, data_all = data_predictions))
list.rbind(loss)[, !duplicated(rownames(list.cbind(loss)))]
}
mean_loss <- function(data_predictions, month_id_task) {
SE_loss_df <- loss_df(data_predictions, "SE")
TADDA1_L1_loss_df <- loss_df(data_predictions, "TADDA1_L1")
# TADDA2_L1_loss_df <- loss_df(data_predictions, "TADDA2_L1")
mean_loss_SE <- colMeans(SE_loss_df[which(SE_loss_df$month_id %in% month_id_task), ])[-1]
mean_loss_TADDA1_L1 <- colMeans(TADDA1_L1_loss_df[which(TADDA1_L1_loss_df[,1] %in% month_id_task), ])[-1]
# mean_loss_TADDA2_L1 <- colMeans(TADDA2_L1_loss_df[which(TADDA2_L1_loss_df[,1] %in% month_id_task), ])[-1]
rbind(mean_loss_SE, mean_loss_TADDA1_L1)
}
# compute predictions for each country, score and prediction horizon
for (country in 1:length(unique(data_fatalities$country_name))) {
current_country_name <- unique(data_fatalities$country_name)[country]; print(current_country_name)
data_country <- data_fatalities %>% filter(country_name == current_country_name) %>% filter(month_id %in% window_months)
# case 1 (uninformed): use log change distribution directly
# list_uninformed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "uninformed", s = step_ahead))
# predictions_uninformed[[country]] <- cbind("country_name" = current_country_name, reduce(list_uninformed, full_join, by = "month_id"))
# case 2 (informed): construct the log change distribution based on current observation and past fatalities
list_informed <- lapply(1:7, function(step_ahead) bayes_acts_predictions(variant = "informed", s = step_ahead))
predictions_informed[[country]] <- cbind("country_name" = current_country_name, reduce(list_informed, full_join, by = "month_id"))
}
# combine lists to data frame and select months that are relevant for evaluation
# data_predictions_uninformed <- merge(data_fatalities, cbind(bind_rows(predictions_uninformed), "No_Change" = 0),
#                                      by = c("country_name", "month_id")) %>% filter(month_id %in% 445:495) # 445:495 comprises both evaluation sets
data_predictions_informed <- merge(data_fatalities, cbind(bind_rows(predictions_informed), "No_Change" = 0),
by = c("country_name", "month_id")) %>% filter(month_id %in% window_months) # 445:495 comprises both evaluation sets
SE_loss_informed_df <- loss_df(data_predictions_informed, "SE")
TADDA1_L1_loss_informed_df <- loss_df(data_predictions_informed, "TADDA1_L1")
# summarise losses
# mean_loss_uninformed_task2 <- mean_loss(data_predictions_uninformed, month_id_task2)
mean_loss_informed_task2 <- mean_loss(data_predictions_informed, month_id_task2); print(round(mean_loss_informed_task2, 3))
mean_loss_informed_task2_train <- mean_loss(data_predictions_informed, 400:444); print(round(mean_loss_informed_task2_train, 3))
data_predictions <- data_predictions_informed
loss <- lapply(1:7, function(s) compute_losses(s, loss = loss_fun, data_all = data_predictions))
loss = "SE"
loss <- lapply(1:7, function(s) compute_losses(s, loss = loss_fun, data_all = data_predictions))
loss_fun = "SE"
loss <- lapply(1:7, function(s) compute_losses(s, loss = loss_fun, data_all = data_predictions))
loss
list.rbind(loss)[, !duplicated(rownames(list.cbind(loss)))]
list.rbind(loss)[, !duplicated(colnames(list.rbind(loss)))]
list.rbind(loss)
loss <- lapply(1:7, function(s) compute_losses(s, loss = loss_fun, data_all = data_predictions))
loss
list.rbind(loss)
